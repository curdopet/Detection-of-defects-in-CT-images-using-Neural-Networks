{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["# run notebooks with functions necessary for this notebook\n","# please modify the path if it differs\n","%run /content/src/image_preprocessing.ipynb"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import cv2\n","import numpy as np\n","import sys\n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pydicom\n","import tensorflow.keras\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from tqdm.notebook import tqdm\n","\n","import wandb\n","from wandb.keras import WandbCallback"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_balanced_train_valid_tuples(dataframe, train_data, valid_data):\n","    \"\"\"\n","    Returns balanced training data IDs and their labels and validation data IDs and labels.\n","        \n","    :param dataframe: the dataframe with image IDs and labels\n","    :param train_data: list with training data studies\n","    :param valid_data: list with validation data studies\n","        \n","    :return: training IDs, training labels, validation IDs, validation labels\n","    \"\"\"\n","    valid_df = dataframe.loc[dataframe['Study'].isin(valid_data)].reset_index().drop(\"index\", axis=1)\n","    train_df = dataframe.loc[dataframe['Study'].isin(train_data)].reset_index().drop(\"index\", axis=1)\n","\n","    one_type_cnt = len(train_df['ID'].unique())//6\n","    balanced = []\n","\n","    for ich_type in [\"epidural\", \"intraventricular\", \"subarachnoid\", \"intraparenchymal\", \"subdural\", \"any\"]:\n","        if ich_type != \"any\":\n","            id_and_label = train_df[train_df['ID'].isin(train_df[(train_df[\"Type\"] == ich_type) & (train_df[\"Label\"] == 1)]['ID'].unique())][['ID', 'Label']]\n","        else:\n","            id_and_label = train_df[train_df['ID'].isin(train_df[(train_df[\"Type\"] == \"any\") & (train_df[\"Label\"] == 0)]['ID'].unique())][['ID', 'Label']]\n","        ids = list(id_and_label['ID'][::6])\n","        labels = np.reshape(id_and_label['Label'].values, (-1, 6))\n","        to_random = list([(i, l) for i, l in zip(ids, labels)])\n","        tmp_values = to_random\n","        while len(to_random) < one_type_cnt:\n","            to_random.extend(tmp_values)\n","\n","        rand_values = random.sample(list(to_random), one_type_cnt)\n","        balanced.extend(rand_values)\n","\n","    return np.array([i[0] for i in balanced]), np.array([i[1] for i in balanced]), valid_df['ID'].values[::6], np.reshape(valid_df['Label'].values, (-1, 6))\n","\n","def get_train_valid_tuples(dataframe, train_data, valid_data):\n","    \"\"\"\n","    Returns training and validation data IDs and their labels.\n","        \n","    :param dataframe: the dataframe with image IDs and labels\n","    :param train_data: list with training data studies\n","    :param valid_data: list with validation data studies\n","        \n","    :return: training IDs, training labels, validation IDs, validation labels\n","    \"\"\"\n","    valid_df = dataframe.loc[dataframe['Study'].isin(valid_data)].reset_index().drop(\"index\", axis=1)\n","    train_df = dataframe.loc[dataframe['Study'].isin(train_data)].reset_index().drop(\"index\", axis=1)\n","    \n","    return train_df['ID'].values[::6], np.reshape(train_df['Label'].values, (-1, 6)), valid_df['ID'].values[::6], np.reshape(valid_df['Label'].values, (-1, 6))"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_neighbors_to_image(image_id, dataframe):\n","    \"\"\"\n","    Finds the neighbouring slices to an image. If there is no neighbours, an array filled with zeros will be returned.\n","        \n","    :param image_id: the image ID for which the neighbours will be found\n","    :param dataframe: the dataframe with image IDs, studies and vertical positions\n","        \n","    :return: (bottom neighbour, top neighbour)\n","    \"\"\"\n","    study_id = dataframe[dataframe['ID'] == image_id][\"Study\"].values[0]\n","    study_ids = dataframe[dataframe['Study'] == study_id][\"ID\"].unique()\n","    positions = []\n","    for img_id in study_ids:\n","        positions.append(dataframe[dataframe['ID'] == img_id][\"Position\"].values[0])\n","    positions_dict = dict(zip(positions, study_ids))\n","    sorted_keys = sorted(positions_dict)\n","    \n","    pos = dataframe[dataframe['ID'] == image_id][\"Position\"].values[0]\n","    pos_index = sorted_keys.index(pos)\n","    \n","    b_neigh_pos = sorted_keys[pos_index - 1] if pos_index != 0 else sorted_keys[pos_index]\n","    b_neigh = positions_dict[b_neigh_pos]\n","    t_neigh_pos = sorted_keys[pos_index + 1] if pos_index != len(sorted_keys) - 1 else sorted_keys[pos_index]\n","    t_neigh = positions_dict[t_neigh_pos]\n","    return b_neigh, t_neigh"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def img_preprocessing(image, b_neigh=None, t_neigh=None, dim=(224,224), window=(40,80), apply_clahe=False):\n","    \"\"\"\n","    Preprocess an CT image using correcting HU values, brain segmentation, new spacing application, reshaping and converting to three channel image.\n","        \n","    :param image: the image to preprocess\n","    :param b_neigh: the bottom neighbouring slice\n","    :param t_neigh: the top neighbouring slice\n","    :param dim: a tuple of the desired dimensions of the image\n","    :param window: a tuple representing the window center and window width\n","    :param apply_clahe: whether to use CLAHE or not\n","        \n","    :return: the preprocessed image\n","    \"\"\"\n","    if b_neigh is not None and t_neigh is not None:\n","        channels = []\n","        for img in (b_neigh, image, t_neigh):\n","            pixel_array = img.pixel_array\n","            pixel_array = hu_to_pixels(pixel_array, img.RescaleIntercept, img.RescaleSlope, window[0], window[1])\n","            pixel_array = segment_brain(pixel_array)\n","            pixel_array = apply_new_spacing(pixel_array, np.array(img.PixelSpacing), [1, 1])\n","            pixel_array = crop_or_reshape(pixel_array, dim)\n","            if apply_clahe:\n","                pixel_array = clahe(pixel_array)\n","            channels.append(pixel_array)\n","        return to_3_channels(channels[0], channels[1], channels[2])\n","    else:\n","        pixel_array = image.pixel_array\n","        pixel_array = hu_to_pixels(pixel_array, image.RescaleIntercept, image.RescaleSlope, window[0], window[1])\n","        pixel_array = segment_brain(pixel_array)\n","        pixel_array = apply_new_spacing(pixel_array, np.array(image.PixelSpacing), [1, 1])\n","        pixel_array = crop_or_reshape(pixel_array, dim)\n","        if apply_clahe:\n","            pixel_array = clahe(pixel_array)\n","        pixel_array = cv2.cvtColor(pixel_array.astype('uint8'), cv2.COLOR_GRAY2BGR)\n","        return pixel_array"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(tensorflow.keras.utils.Sequence):\n","    \"\"\"\n","    A class for training and test data generator.\n","    \"\"\"\n","    def __init__(self, list_IDs, labels, img_path, dataframe=None, batch_size=32, dim=(224,224), n_classes=1, shuffle=True, \n","                 window=(40, 80), context3d=True, augment=True, clahe=False, noise=False, image_format='jpg'):\n","        \"\"\"\n","        :param list_IDS: the list of IDs of the data to generate\n","        :param labels: labels corresponding to the IDs\n","        :param img_path: a path to the images which will be generated\n","        :param dataframe: a dataframe with the data IDs, studies and position - required only when the data format is dicom\n","        :param batch_size: the batch size of the input data\n","        :param dim: the dimensions of the image data\n","        :param n_classes: the number of predicted classes\n","        :param shuffle: whether to randomly shuffle data or not\n","        :param window: the window to use on dicom images\n","        :param context3d: whether to use 3D context or not\n","        :param augment: whether to augment the data or not\n","        :param clahe: whether to apply CLAHE on the images\n","        :param noise: whether to add noise to the images\n","        :param image_format: the format of the images - supported are \"jpg\" and \"dicom\"\n","        \"\"\"\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.labels = labels\n","        self.list_IDs = list_IDs\n","        self.img_path = img_path\n","        self.dataframe = dataframe\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        \n","        self.window = window\n","        self.augmentation = DataAugmentation(123, max_angle=30)\n","        self.augment = augment\n","        self.context3d = context3d\n","        self.clahe = clahe\n","        self.noise = noise\n","        self.image_format = image_format\n","        \n","        self.on_epoch_end()\n","    \n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","            \n","    def __data_generation(self, list_IDs_temp, indexes):\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim, 3))\n","        y = np.empty((self.batch_size, self.n_classes), dtype=int)\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            if IMAGE_FORMAT == \"jpg\":\n","                sample = cv2.imread(self.img_path + ID + \".jpg\")\n","            elif IMAGE_FORMAT == \"dicom\":\n","                sample = pydicom.filereader.dcmread(self.img_path + ID + \".dcm\")\n","                if self.context3d and self.dataframe is None:\n","                    print('If you do not include the dataframe, the 3D context will not be generated.')\n","                    sample = img_preprocessing(sample, None, None, self.dim, self.window, self.clahe)\n","                elif self.context3d:\n","                    b_neigh, t_neigh = find_neighbors_to_image(ID, self.dataframe)\n","                    b_neigh = cv2.imread(self.img_path + b_neigh + \".jpg\")\n","                    t_neigh = cv2.imread(self.img_path + t_neigh + \".jpg\")\n","                    sample = img_preprocessing(sample, b_neigh, t_neigh, self.dim, self.window, self.clahe)\n","                else:\n","                    sample = img_preprocessing(sample, None, None, self.dim, self.window, self.clahe)\n","            else:\n","                print(f'Format \"{self.image_format}\" is not supported. Valid formats are \"jpg\" or \"dicom\".')\n","            \n","            if self.augment:\n","                X[i,] = self.augmentation.random_augment(sample, self.noise)\n","            else:\n","                X[i,] = sample\n","            y[i] = self.labels[indexes[i]]\n","        \n","        return X, y\n","    \n","    def __len__(self):\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","    \n","    def __getitem__(self, index):\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","        X, y = self.__data_generation(list_IDs_temp, indexes)\n","\n","        return X, y"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def weighted_multi_label_log_loss(y_true, y_pred):\n","    \"\"\"\n","    Log loss function with doubled weight on 'any' label.\n","    \n","    :param y_true: the ground truth labels\n","    :param y_pred: the predicted labels\n","    \n","    :return: the loss\n","    \"\"\"\n","    weights = [1., 1., 1., 1., 1., 2.]\n","    eps = tf.keras.backend.epsilon()\n","    \n","    new_y_true = tf.cast(y_true, tensorflow.float32)\n","    new_y_pred = tf.keras.backend.clip(y_pred, eps, 1.0-eps)\n","\n","    out = -(         new_y_true  * tf.keras.backend.log(      new_y_pred) * weights\n","            + (1.0 - new_y_true) * tf.keras.backend.log(1.0 - new_y_pred) * weights)\n","    \n","    return tf.keras.backend.mean(out, axis=-1)"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ComputeAnyLabel(tf.keras.layers.Layer):\n","    \"\"\"\n","    A layer which computes the 'any' label as the max value of other labels.\n","    \"\"\"\n","    def __init__(self, num_outputs):\n","        super(ComputeAnyLabel, self).__init__()\n","        self.num_outputs = num_outputs\n","\n","    def build(self, input_shape):\n","        pass\n","\n","    def call(self, input_tensor):\n","        input_max = tf.reshape(tf.math.reduce_max(input_tensor,axis=1), (len(input_tensor),1))\n","        return tf.concat([input_tensor, input_max], 1)"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model(base, shape, pooling, optimizer, lr, loss, metrics, weights=None):\n","    \"\"\"\n","    Creates and compiles a CNN model.\n","    \n","    :param base: the base architecture to use\n","    :param shape: the shape of the input data\n","    :param pooling: the pooling to use in the model\n","    :param optimizer: the optimizer to use during the model training\n","    :param lr: the learning rate to use during the model training\n","    :param loss: the loss function to use during the model training\n","    :param metrics: the metrics to use for the model evaluation\n","    :param weights: the initialization weights of the model\n","    \n","    :return: a compiled model\n","    \"\"\"\n","    if base == \"DenseNet121\":\n","        xbase_model = tf.keras.applications.DenseNet121\n","    elif base == \"DenseNet169\":\n","        xbase_model = tf.keras.applications.DenseNet121\n","    elif base == \"DenseNet201\":\n","        xbase_model = tf.keras.applications.DenseNet121\n","    elif base == \"EfficientNetB0\":\n","        xbase_model = tf.keras.applications.EfficientNetB0\n","    elif base == \"EfficientNetB1\":\n","        xbase_model = tf.keras.applications.EfficientNetB1\n","    elif base == \"EfficientNetB2\":\n","        xbase_model = tf.keras.applications.EfficientNetB2\n","    elif base == \"EfficientNetB3\":\n","        xbase_model = tf.keras.applications.EfficientNetB3\n","    elif base == \"EfficientNetB4\":\n","        xbase_model = tf.keras.applications.EfficientNetB4\n","    elif base == \"EfficientNetB5\":\n","        xbase_model = tf.keras.applications.EfficientNetB5\n","    elif base == \"InceptionV3\":\n","        xbase_model = tf.keras.applications.InceptionV3\n","    elif base == \"InceptionResNetV2\":\n","        xbase_model = tf.keras.applications.InceptionResNetV2\n","    elif base == \"ResNet50\":\n","        xbase_model = tf.keras.applications.ResNet50\n","    elif base == \"ResNet50V2\":\n","        xbase_model = tf.keras.applications.ResNet50V2\n","    elif base == \"ResNet101\":\n","        xbase_model = tf.keras.applications.ResNet101\n","    elif base == \"ResNet101V2\":\n","        xbase_model = tf.keras.applications.ResNet101V2\n","    elif base == \"ResNet152\":\n","        xbase_model = tf.keras.applications.ResNet152\n","    elif base == \"ResNet152V2\":\n","        xbase_model = tf.keras.applications.ResNet152V2\n","    else:\n","        print(f'Model {base} is not supported. Please use an another model or modify the create_model() function in model_functions.ipynb.')\n","\n","    base_model = xbase_model(input_shape=shape, pooling=pooling, include_top=False)\n","    model = tf.keras.models.Model(inputs=base_model.input, \n","                                  outputs=ComputeAnyLabel(6)(tf.keras.layers.Dense(5, activation=\"sigmoid\")(base_model.output)))\n","    if weights is not None:\n","        model.load_weights(weights)\n","    model.compile(optimizer=optimizer(lr), loss=loss, metrics=metrics)\n","    return model"],"metadata":{},"execution_count":null,"outputs":[]}]}