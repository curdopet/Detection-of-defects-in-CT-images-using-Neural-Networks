{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# run notebooks with functions necessary for this notebook\n# please modify the path if it differs\n%run model_functions.ipynb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport cv2\nimport numpy as np\nimport sys\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pydicom\nimport tensorflow.keras\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\n\nimport wandb\nfrom wandb.keras import WandbCallback\n\n\n#######################################################\n#                  EXPERIMENT SETTINGS                #\n#                                                     #\n# please modify if you want to use different settings #\n#######################################################\n\nTRAIN_IMG_PATH = \"/dataset/jpg/\" # path to the directory with imput images\nTRAIN_DF_PATH = \"dataframes/experiments.csv\"\nrandom.seed(12345)\n\n# jpg data are preprocessed, so the training is faster, but they cannot use preprocessing techniques as dicom can\nIMAGE_FORMAT = \"jpg\" # valid values are \"jpg\" or \"dicom\"\n\nARCHITECTURE = [\"EfficientNetB0\", \"DenseNet121\", \"InceptionV3\", \"ResNet50\"]\nPOOLING = [\"avg\", \"max\"]\nBATCH_SIZE = [8, 16, 32, 64]\nEPOCHS = 1\nLEARNING_RATE = [0.00005, 0.00002, 0.00001, 0.000005]\nDECAY_STEPS = [500, 1000, 1500]\nDECAY_RATE = [0.95, 0.97, 0.99]\nMETRICS = [tf.keras.metrics.AUC(multi_label=True)]\nOPTIMIZER = tf.keras.optimizers.Adam\n\nNOISE = [True, False]\nBALANCED = [True, False]\n\n# jpg data are preprocessed, so this setting won't have impact on the data\n# in the case you want to experiment with preprocessing, download preprocessed jpeg data with desired settings or use dicom data\nWINDOW_WIDTH = [80, 200]\nWINDOW_CENTER = [40, 80]\nCONTEXT_3D = [True, False]\nCLAHE = [True, False]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, training_generator, validation_generator, config):\n    \"\"\"\n    Trains a CNN model and plots the process using wandb.ai.\n    \n    :param model: the CNN model to train\n    :param training_generator: a generator of the training data\n    :param validation_generator: a generator of the validation data\n    :param config: a wandb.ai config\n    \"\"\"\n    for i in range(config.epochs):\n        print(f'Epoch {i+1}')\n        model.fit(x=training_generator, epochs=1, callbacks=[WandbCallback()])\n        loss, auc = model.evaluate(x=validation_generator, callbacks=[WandbCallback()])\n        wandb.log({'val_loss': loss, 'val_auc': auc})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_validation():\n    \"\"\"\n    Cross-validates a CNN model.\n    \"\"\"\n    dataframe = pd.read_csv(TRAIN_DF_PATH)\n    rd_seed = 123\n    n_splits = 3\n    \n    wandb.init(config={\"epochs\": EPOCHS,\n                       \"loss_function\": \"weighted_multi_label_log_loss\",\n                       \"desc\": \"\"\n                      })\n    config = wandb.config\n    \n    dataframe.drop(index=dataframe.loc[dataframe['ID'] == \"ID_6431af929\"].index, inplace=True)\n    dataframe.drop(index=dataframe.loc[dataframe['ID'] == \"ID_00de64f80\"].index, inplace=True)\n    studies = dataframe['Study'].unique()\n    \n    for i, (train, valid) in enumerate(KFold(n_splits=n_splits, shuffle=True, random_state = rd_seed).split(studies)):\n        print(f'Cross-validation fold {i}')\n        tf.keras.backend.clear_session()\n        if config.balanced:\n            X_train, y_train, X_valid, y_valid = get_balanced_train_valid_tuples(dataframe, studies[train], studies[valid])\n        else:\n            X_train, y_train, X_valid, y_valid = get_train_valid_tuples(dataframe, studies[train], studies[valid])\n            \n        training_generator = DataGenerator(X_train, y_train, TRAIN_IMG_PATH, dataframe, batch_size=config.batch_size, dim=(224, 224), n_classes=6, shuffle=True, window=(config.window_center, config.window_width), context3d=config.context3d, clahe=config.clahe, noise=config.noise, image_format=IMAGE_FORMAT)\n        validation_generator = DataGenerator(X_valid, y_valid, TRAIN_IMG_PATH, dataframe, batch_size=config.batch_size, dim=(224, 224), n_classes=6, shuffle=True, window=(config.window_center, config.window_width), context3d=config.context3d, augment=False, clahe=config.clahe, noise=config.noise, image_format=IMAGE_FORMAT)\n    \n        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=config.learning_rate, decay_steps=config.decay_steps, decay_rate=config.decay_rate)\n        model = create_model(config.architecture, (224, 224, 3), config.pooling, OPTIMIZER, lr_schedule, weighted_multi_label_log_loss, METRICS)\n    \n        train_model(model, training_generator, validation_generator, config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n  'method': 'grid', \n  'metric': {\n      'name': 'val_loss',\n      'goal': 'minimize'\n  },\n  'parameters': {\n      'batch_size': {\n          'values': BATCH_SIZE\n      },\n      'learning_rate':{\n          'values': LEARNING_RATE\n      },\n      'decay_steps':{\n          'values': DECAY_STEPS\n      },\n      'decay_rate':{\n          'values': DECAY_RATE \n      },\n      'context3d':{\n          'values': CONTEXT_3D\n      },\n      'clahe':{\n          'values': CLAHE\n      },\n      'window_width':{\n          'values': WINDOW_WIDTH\n      },\n      'window_center':{\n          'values': WINDOW_CENTER\n      },\n      'pooling':{\n          'values': POOLING\n      },\n      'architecture': {\n          'values': ARCHITECTURE\n      },\n      'noise': {\n          'values': NOISE\n      },\n      'balanced': {\n          'values': BALANCED\n      }\n  }\n}\n\nsweep_id = wandb.sweep(sweep_config, project=\"Detection-of-defects-in-CT-images\")\nwandb.agent(sweep_id, function=cross_validation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}