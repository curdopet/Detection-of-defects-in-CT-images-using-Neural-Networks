{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow.keras\n","import pandas as pd\n","import wandb\n","\n","from tqdm.notebook import tqdm\n","from wandb.keras import WandbCallback\n","from sklearn.model_selection import KFold\n","\n","%run /content/src/model_functions.ipynb"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_metrics(y_test, predictions):\n","    auc = tf.keras.metrics.AUC(multi_label=True)\n","    accuracy = tf.keras.metrics.Accuracy()\n","    tn = tf.keras.metrics.TrueNegatives()\n","    tp = tf.keras.metrics.TruePositives()\n","    fn = tf.keras.metrics.FalseNegatives()\n","    fp = tf.keras.metrics.FalsePositives()\n","\n","    tn.update_state(y_test, predictions)\n","    tp.update_state(y_test, predictions)\n","    fn.update_state(y_test, predictions)\n","    fp.update_state(y_test, predictions)\n","    auc.update_state(y_test, predictions)\n","    accuracy.update_state(y_test, np.around(predictions))\n","    print(f'AUC: {auc.result().numpy()}, ' +\n","          f'accuracy: {accuracy.result().numpy()}, ' +\n","          f'sensitivity: {tp.result().numpy()/(tp.result().numpy()+fn.result().numpy())}, ' +\n","          f'specificity: {tn.result().numpy()/(tn.result().numpy()+fp.result().numpy())}')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the final model"],"metadata":{}},{"cell_type":"code","source":["RD_SEED = 123\n","N_SPLITS = 3\n","EPOCHS = 5\n","TRAIN_DF_PATH = \"/content/dataframes/train_final.csv\"\n","TRAIN_IMG_PATH = \"/content/jpg_data/stage_2_train_jpg/\"\n","\n","ARCHITECTURE = \"DenseNet121\" # or \"EfficientNet121\"\n","BATCH_SIZE = 32\n","DIM = (224, 224)\n","N_CLASSES = 6\n","WINDOW = (40, 80)\n","IMAGE_FORMAT = 'jpg'\n","LEARNING_RATE = 0.00001      # or 0.00002\n","POOLING = 'avg'\n","METRICS = [tf.keras.metrics.AUC(multi_label=True)]\n","OPTIMIZER = tf.keras.optimizers.Adam\n","\n","LOAD_WEIGHTS_PATH = None     # path to weights you want to use for training \n","SAVE_WEIGHTS = True\n","OUTPUT_DIR = \"/content/weights/\"\n","\n","# in the case of limited runtime or the preference of running a specific fold:\n","RUN_SINGLE_FOLD = False\n","FOLD = 1"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = pd.read_csv(TRAIN_DF_PATH)\n","\n","dataframe.drop(index=dataframe.loc[dataframe['ID'] == \"ID_6431af929\"].index, inplace=True)\n","dataframe.drop(index=dataframe.loc[dataframe['ID'] == \"ID_00de64f80\"].index, inplace=True)\n","studies = dataframe['Study'].unique()\n","    \n","for i, (train, valid) in enumerate(KFold(n_splits=N_SPLITS, shuffle=True, random_state=RD_SEED).split(studies)):\n","    print(f'Cross-validation fold {i+1}')\n","    if RUN_SINGLE_FOLD and i+1 != FOLD:\n","        print(\"Skipped...\")\n","        continue\n","        \n","    tf.keras.backend.clear_session()\n","    model = create_model(ARCHITECTURE, (224, 224, 3), POOLING, OPTIMIZER, LEARNING_RATE, weighted_multi_label_log_loss, METRICS, LOAD_WEIGHTS_PATH)\n","    \n","    for epoch in range(EPOCHS):\n","        print(f'Epoch {epoch+1}')\n","        \n","        X_train, y_train, X_valid, y_valid = get_balanced_train_valid_tuples(dataframe, studies[train], studies[valid])\n","        training_generator = DataGenerator(X_train, y_train, TRAIN_IMG_PATH, dataframe, BATCH_SIZE, DIM, N_CLASSES, shuffle=True, window=WINDOW, image_format=IMAGE_FORMAT)\n","        validation_generator = DataGenerator(X_valid, y_valid, TRAIN_IMG_PATH, dataframe,BATCH_SIZE, DIM, N_CLASSES, shuffle=True, window=WINDOW, augment=False, image_format=IMAGE_FORMAT)\n","\n","        model.fit(x=training_generator, epochs=1)\n","        if SAVE_WEIGHTS:\n","            model.save_weights(OUTPUT_DIR + \"weights_\" + ARCHITECTURE + \"_fold_\" + str(i+1) + \"_epoch_\" + str(epoch+1) + \".h5\")\n","        model.evaluate(x=validation_generator)\n","    \n","    if SAVE_WEIGHTS:\n","        model.save_weights(OUTPUT_DIR + \"weights_\" + ARCHITECTURE + \"_fold_\" + str(i+1) + \".h5\")"],"metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate the model on custom test set"],"metadata":{}},{"cell_type":"code","source":["TEST_DF_PATH = \"/content/dataframes/test_final.csv\"\n","TEST_IMG_PATH = \"/content/jpg_data/stage_2_train_jpg/\"\n","\n","ARCHITECTURE = \"DenseNet121\"   # or \"EfficientNet121\"\n","BATCH_SIZE = 32\n","LEARNING_RATE = 0.00001        # or 0.00002\n","POOLING = 'avg'\n","METRICS = [tf.keras.metrics.AUC(multi_label=True)]\n","OPTIMIZER = tf.keras.optimizers.Adam\n","\n","WEIGHTS_DIR = \"/content/weights/\"\n","WEIGHTS = \"weights_DenseNet121_fold_1.h5\"  # modify to use other weights\n","USE_TTA = True\n","SAVE_PREDICTIONS = True\n","OUTPUT_DIR = \"/content/predictions/\""],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(model, batches, img_path, tta):\n","    predictions = []\n","    augmentation = DataAugmentation(123, max_angle=30)\n","    \n","    for batch in tqdm(batches):\n","        samples = np.empty((len(batch), 224, 224, 3))\n","        for i, ID in enumerate(batch):\n","            samples[i] = cv2.imread(img_path + ID + \".jpg\") # TODO: add dicom possibility\n","\n","        if not tta:\n","            predictions.extend(model.predict(samples))\n","        else:\n","            n_samples = 5\n","            sample_predictions = []\n","            for n in range(n_samples):\n","                aug_samples = np.empty((len(batch), 224, 224, 3))\n","                for s in range(len(batch)):\n","                    aug_samples[s] = augmentation.random_augment(samples[s], False)\n","                sample_predictions.append(model.predict(aug_samples))\n","            sample_predictions = np.array(sample_predictions)\n","            predictions.extend([[sample_predictions[:,y,x].sum()/n_samples for x in range(6)] for y in range(len(batch))])\n","    return np.array(predictions)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = pd.read_csv(TEST_DF_PATH)\n","\n","X_test, y_test = dataframe['ID'].values[::6], np.reshape(dataframe['Label'].values, (-1, 6))\n","X_test_batches = np.array_split(X_test, len(X_test)//BATCH_SIZE)\n","\n","tf.keras.backend.clear_session()\n","model = create_model(ARCHITECTURE, (224, 224, 3), POOLING, OPTIMIZER, LEARNING_RATE, weighted_multi_label_log_loss, METRICS, WEIGHTS_DIR + WEIGHTS)\n","\n","predictions = predict(model, X_test_batches, TEST_IMG_PATH, USE_TTA)\n","\n","if SAVE_PREDICTIONS:\n","    pd.DataFrame(predictions).to_csv(OUTPUT_DIR + WEIGHTS[:-3] + (\"_TTA\" if USE_TTA else \"\") + \"_predictions.csv\", index=False)\n","\n","print_metrics(y_test, predictions)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ensembling the predictions"],"metadata":{}},{"cell_type":"code","source":["TEST_DF_PATH = \"/content/dataframes/test_final.csv\"\n","PREDICTIONS_DIR = \"/content/predictions/\"\n","PREDICTIONS_FILES = [\"pred1.csv\", \"pred2.csv\", \"pred3.csv\"] # specify the predictions files\n","SAVE_PREDICTIONS = False\n","OUTPUT_DIR = \"/content/predictions/\"\n","OUTPUT_FILE = \"DenseNet121_ensemble_predictions.csv\" # modify if you want to use another file name"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df = pd.read_csv(TEST_DF_PATH)\n","y_test = np.reshape(test_df['Label'].values, (-1, 6))\n","\n","predictions = np.zeros_like(y_test).astype('float64')\n","for file in PREDICTIONS_FILES:\n","    df = pd.read_csv(PREDICTIONS_DIR + file)\n","    predictions += df.to_numpy()\n","predictions /= len(PREDICTIONS_FILES)\n","\n","if SAVE_PREDICTIONS:\n","    pd.DataFrame(predictions).to_csv(OUTPUT_DIR + OUTPUT_FILE, index=False)\n","\n","print_metrics(y_test, predictions)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict the submission dataset"],"metadata":{}},{"cell_type":"code","source":["MOD_SUBMISSION_DF_PATH = \"/content/dataframes/stage_2_sample_submission_mod.csv\"\n","SUBMISSION_IMG_PATH = \"/content/jpg_data/stage_2_test_jpg/\"\n","ORIG_SUBMISSION_DF_PATH = \"/content/drive/MyDrive/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\"\n","\n","ARCHITECTURE = \"DenseNet121\"   # or \"EfficientNet121\"\n","BATCH_SIZE = 32\n","LEARNING_RATE = 0.00001        # or 0.00002\n","POOLING = 'avg'\n","METRICS = [tf.keras.metrics.AUC(multi_label=True)]\n","OPTIMIZER = tf.keras.optimizers.Adam\n","\n","WEIGHTS_DIR = \"/content/weights/\"\n","WEIGHTS = \"weights_DenseNet121_fold_1.h5\" # specify the weights you want to use\n","USE_TTA = True\n","SAVE_PREDICTIONS = True\n","OUTPUT_DIR = \"/content/predictions/\"\n","OUTPUT_FILE = \"DenseNet121_fold_1_submission.csv\" # modify if you want to use another file name"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = pd.read_csv(MOD_SUBMISSION_DF_PATH)\n","\n","X_test = dataframe['ID'].values[::6]\n","X_test_batches = np.array_split(X_test, len(X_test)//BATCH_SIZE)\n","\n","tf.keras.backend.clear_session()\n","model = create_model(ARCHITECTURE, (224, 224, 3), POOLING, OPTIMIZER, LEARNING_RATE, weighted_multi_label_log_loss, METRICS, WEIGHTS_DIR + WEIGHTS)\n","\n","predictions = predict(model, X_test_batches, SUBMISSION_IMG_PATH, USE_TTA)\n","\n","submission_df = pd.read_csv(ORIG_SUBMISSION_DF_PATH)\n","submission_df['Label'] = predictions.flatten()\n","\n","if SAVE_PREDICTIONS:\n","    submission_df.to_csv(OUTPUT_DIR + OUTPUT_FILE, index=False)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ensembling submissions"],"metadata":{}},{"cell_type":"code","source":["ORIG_SUBMISSION_DF_PATH = \"/content/drive/MyDrive/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\"\n","PREDICTIONS_DIR = \"/content/predictions/\"\n","SUBMISSION_FILES = [\"sub1.csv\", \"sub2.csv\", \"sub3.csv\", \"sub4.csv\", \"sub5.csv\"] # specify the predictions files\n","SAVE_PREDICTIONS = True\n","OUTPUT_DIR = \"/content/predictions/\"\n","OUTPUT_FILE = \"EfficientDenseNet_ensemble_submission.csv\" # modify if you want to use another file name"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub_df = pd.read_csv(ORIG_SUBMISSION_DF_PATH)\n","y_sub = sub_df['Label'].values\n","\n","submissions = np.zeros_like(y_sub).astype('float64')\n","for file in SUBMISSION_FILES:\n","    df = pd.read_csv(PREDICTIONS_DIR + file)\n","    submissions += df['Label'].values\n","submissions /= len(SUBMISSION_FILES)\n","sub_df['Label'] = submissions\n","\n","if SAVE_PREDICTIONS:\n","    sub_df.to_csv(OUTPUT_DIR + OUTPUT_FILE, index=False)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}