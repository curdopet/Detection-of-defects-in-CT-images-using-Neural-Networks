# Detection of defects in CT images using Neural Networks

This repository contains a bachelor thesis (and its source codes) that aims to research and implement a possible solution of the RSNA Intracranial Hemorrhage competition.

The repository structure is following:
```
|
+ src                   directory with source codes
+ weights               directory with final model's weights 
+ thesis                directory with the thesis and LaTeX code
   + images             directory with images for the thesis
```

## Data
The data aren't provided in this repository. They can be downloaded from the RSNA Intracranial Hemorrhage competition site on Kaggle. But you must be registered on Kaggle to be able to download the data.

## Running the code
All the code is in the src directory. These notebooks used to be run on Kaggle and Google Colab, but the paths are configured to the Google Colab environment, so if you want to use it on Kaggle, you must modify the paths in the source code.

The directory in Google Colab must have the following structure:
```
|
+ rsna-intracranial-hemorrhage-detection    directory downloaded from the Kaggle competition
|  + stage_2_train                          directory with the DICOM training data
|  + stage_2_test                           directory with the DICOM test data
+ dataframes                                directory for the custom dataframes generated by the notebooks
+ jpg_data                                  directory for the data jpg generated by the notebooks
|  + stage_2_train_jpg                      directory for the jpg training data
|  + stage_2_test_jpg                       directory for the jpg test data
+ weights                                   directory with the pre-trained weights
+ src                                       directory with the source notebooks
```
Also, note that some required packages have to be installed in the Google Colab environment. The packages that need to be installed are ```pydicom``` and ```wandb```.
### Preparing the dataframes
The first thing which has to be done is to prepare the dataframes. For running the notebooks is necessary to add more information into the dataframes and modify them. It can be done by running the dataframe_preprocessing.ipynb in the src directory.
### Preparing the data
Because preprocessing the images during the training is extremely time-consuming, it is recommended to preprocess all data before the training and convert it to JPEG format to save some space. The notebook for the conversion is convert_data_to_jpg.ipynb in the src directory. Note that the conversion also takes time, so it is possible to run it multiple in parallel.
### Experiments
The experiments can be run by the experiments.ipynb in the src directory. If you want, you can modify the experiment settings. Also, notice that the experiments' results are plotted by wandb.ai, so you probably have to create an account there.
**TODO: modify notebooks to be run without wandb.ai** 
The experiments can be run with both JPEG and DICOM data, but using the JPEG data is recommended.
### Training the final solution and evaluation
The final solution is trained in the final_model.ipynb in the src directory. In this notebook, the models can also be evaluated on the test data, and the submissions dataframe for the competition can be generated.